{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "# import requests\n",
    "import random\n",
    "import os\n",
    "import json\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display\n",
    "import gc\n",
    "import torch.nn as nn\n",
    "from typing import List\n",
    "from numpy import ndarray\n",
    "import pdb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import BuildVQADatasetSingleLanguage, VQADatasetSingleLanguage, MedVQADataset\n",
    "from CFG_awx import CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['El liquen dorado es un tipo de enfermedad de la piel pigmentada púrpura.', '¿Liquen Dorado Amarillo?', 'Patología.']\n",
      "56 Question: Esto ocurre todos los veranos, sólo en la parte inferior de la pierna. Desaparece sola en un mes. Pica bastante. Empieza como una pequeña mancha roja, que va creciendo poco a poco.\n",
      "100 Question: Descripción de la situación: Niña de 2 años.  Tiene dos pequeñas masas en el muslo izquierdo, \n",
      "en la zona de pliegue entre la nalga y la parte posterior del muslo.  Las masas son congénitas, pero no se detectaron al nacimiento, \n",
      "y crecieron con relativa rapidez antes de cumplir un año.  No se realizó tratamiento. Visualmente, se están extendiendo muy \n",
      "lentamente a ambos lados.  No pican ni duelen ni molestan.  Piel suave, sin sensación de hinchazón. \n",
      "No alteración cutánea en el lugar de una nueva lesión, ni donde originalmente crecían las masas.  \n",
      "Hay un poco de escarificación cuando se seca en otoño e invierno. Otras observaciones: Es fácil dejar cicatrices en la piel de la niña.  \n",
      "La piel es blanquecina después de la curación de picaduras.  La cicatriz es plana. ¿Puedo pedirle a un médico que le eche un vistazo?\n",
      "  Muchas gracias.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_dir = CFG.train_groups\n",
    "\n",
    "train_img_paths = list(map(lambda x: os.path.join(train_dir, x), os.listdir(train_dir)))\n",
    "train_dataset_es = BuildVQADatasetSingleLanguage(transforms=CFG.data_transforms['train'], \n",
    "                                json_file=CFG.train_json,\n",
    "                                train_dir=CFG.train_groups,\n",
    "                                language = 'content_es')\n",
    "\n",
    "\n",
    "val_dir = CFG.valid_groups\n",
    "\n",
    "val_img_paths = list(map(lambda x: os.path.join(val_dir, x), os.listdir(val_dir)))\n",
    "val_dataset_es = BuildVQADatasetSingleLanguage(transforms=CFG.data_transforms['valid'], \n",
    "                                json_file=CFG.valid_json,\n",
    "                                train_dir=CFG.valid_groups, train=False,\n",
    "                                language='content_es')\n",
    "\n",
    "\n",
    "test_dir = CFG.test_groups\n",
    "test_dataset_es = BuildVQADatasetSingleLanguage(transforms=CFG.data_transforms['valid'], \n",
    "                                json_file=CFG.test_json,\n",
    "                                train_dir=CFG.test_groups, train=False,\n",
    "                                language='content_es')\n",
    "idx = 42\n",
    "\n",
    "print(train_dataset_es[idx][3])\n",
    "# print(f\"Question: {val_dataset_es[idx][2]}\")\n",
    "print(len(val_dataset_es), f\"Question: {val_dataset_es[idx][2]}\")\n",
    "print(len(test_dataset_es), f\"Question: {test_dataset_es[idx][2]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  (encounter_id, self.language), images, question, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All keys matched succesfully\n",
      "PathGen loaded succesfully\n"
     ]
    }
   ],
   "source": [
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-16')\n",
    "model.load_state_dict(torch.load('pathgenclip.pt'))\n",
    "print(\"All keys matched succesfully\")\n",
    "model.eval()\n",
    "print(\"PathGen loaded succesfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = train_dataset_es[0][1]\n",
    "image = image.permute(0, 3, 1, 2)\n",
    "image.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_image_features(dataset, model, split, feature_dir, recompute=False):\n",
    "    \"\"\"\n",
    "    Extract image features using a pre-trained model and save them to disk,\n",
    "    with an option to recompute existing features.\n",
    "    \n",
    "    Args:\n",
    "        dataset (torch.utils.data.Dataset): The dataset containing the images.\n",
    "        model (torch.nn.Module): The pre-trained model used for feature extraction.\n",
    "        split (str): The dataset split ('train', 'valid', or 'test').\n",
    "        recompute (bool): If True, recompute features even if files already exist.\n",
    "    \"\"\"\n",
    "    # feature_dir = \"Features/pathgen\"\n",
    "    os.makedirs(f'{feature_dir}/{split}', exist_ok=True)\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        img_id = dataset[i][0][0]\n",
    "        output_file = os.path.join(feature_dir, split, f'{img_id}.pt')\n",
    "        \n",
    "        # Check if the file already exists and recompute flag\n",
    "        if recompute or not os.path.exists(output_file):\n",
    "            with torch.no_grad(), torch.amp.autocast(device_type='cuda'):\n",
    "                image = dataset[i][1]\n",
    "                image = image.permute(0, 3, 1, 2)\n",
    "                image_features = model.encode_image(image)\n",
    "                torch.save(image_features, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = 'pathgen'\n",
    "feature_dir = os.path.join('Features', feature_extractor)\n",
    "extract_image_features(dataset=val_dataset_es, model=model, split='valid', feature_dir=feature_dir, recompute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_extractor = 'pathgen'\n",
    "# feature_dir = os.path.join('Features', feature_extractor)\n",
    "# extract_image_features(dataset=test_dataset_es, model=model, split='test', feature_dir=feature_dir, recompute=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# idx = 0\n",
    "# img_ids = []\n",
    "# img_paths = []\n",
    "# all_questions = []\n",
    "# all_answers = []\n",
    "# img_dict = {} \n",
    "# for idx in tqdm(range(len(train_dataset_es))):\n",
    "#     d = train_dataset_es[idx]\n",
    "#     img_id = d[0][0]\n",
    "#     filename = f'{img_id}.jpg'\n",
    "#     prefix_i = model.encode_image(d[1].permute(0, 3, 1, 2)).cpu()  \n",
    "#     question = d[2]\n",
    "#     answer = d[3]\n",
    "#     if img_id not in img_dict.keys():\n",
    "#         img_dict[img_id] = [[question],answer,prefix_i,filename]\n",
    "#     else:\n",
    "#         img_dict[img_id][0].append(question)\n",
    "#         img_dict[img_id][1].append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_img_prefixes = []\n",
    "\n",
    "# for img_id, imgs in enumerate(img_dict.keys()):\n",
    "#     all_img_prefixes.append(img_dict[imgs][2])\n",
    "#     all_questions.append(img_dict[imgs][0])\n",
    "    \n",
    "        \n",
    "#     all_answers.append(img_dict[imgs][1])\n",
    "#     img_ids.append(img_id)\n",
    "#     img_paths.append(img_dict[imgs][2])\n",
    "\n",
    "# all_data = {\"img_prefix\": torch.cat(all_img_prefixes, dim=0), \"img_ids\": img_ids, \"questions\": all_questions,'answers': all_answers,'img_path': img_paths}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = MedVQADataset(data=train_dataset_es)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   79.,  2301., 44424.,  ...,     0.,     0.,     0.])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[42][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0.9904, 0.7826, 0.7236],\n",
       "           [0.9907, 0.7874, 0.7319],\n",
       "           [0.9938, 0.8013, 0.7540],\n",
       "           ...,\n",
       "           [0.6743, 0.4870, 0.3756],\n",
       "           [0.6784, 0.4927, 0.3796],\n",
       "           [0.6742, 0.4891, 0.3742]],\n",
       " \n",
       "          [[0.9866, 0.7769, 0.7173],\n",
       "           [0.9869, 0.7832, 0.7274],\n",
       "           [0.9885, 0.7966, 0.7479],\n",
       "           ...,\n",
       "           [0.6713, 0.4848, 0.3721],\n",
       "           [0.6759, 0.4906, 0.3768],\n",
       "           [0.6712, 0.4858, 0.3710]],\n",
       " \n",
       "          [[0.9874, 0.7733, 0.7145],\n",
       "           [0.9858, 0.7770, 0.7213],\n",
       "           [0.9867, 0.7950, 0.7448],\n",
       "           ...,\n",
       "           [0.6726, 0.4821, 0.3705],\n",
       "           [0.6741, 0.4847, 0.3724],\n",
       "           [0.6691, 0.4791, 0.3655]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.9410, 0.7683, 0.6703],\n",
       "           [0.9391, 0.7664, 0.6685],\n",
       "           [0.9401, 0.7653, 0.6673],\n",
       "           ...,\n",
       "           [0.0351, 0.0278, 0.0319],\n",
       "           [0.0311, 0.0242, 0.0281],\n",
       "           [0.0290, 0.0227, 0.0264]],\n",
       " \n",
       "          [[0.9312, 0.7570, 0.6598],\n",
       "           [0.9329, 0.7586, 0.6615],\n",
       "           [0.9342, 0.7580, 0.6608],\n",
       "           ...,\n",
       "           [0.0570, 0.0472, 0.0562],\n",
       "           [0.0428, 0.0307, 0.0413],\n",
       "           [0.0338, 0.0227, 0.0338]],\n",
       " \n",
       "          [[0.9326, 0.7583, 0.6611],\n",
       "           [0.9341, 0.7596, 0.6625],\n",
       "           [0.9335, 0.7570, 0.6600],\n",
       "           ...,\n",
       "           [0.0611, 0.0512, 0.0607],\n",
       "           [0.0441, 0.0315, 0.0428],\n",
       "           [0.0335, 0.0220, 0.0339]]],\n",
       " \n",
       " \n",
       "         [[[0.2059, 0.1275, 0.1000],\n",
       "           [0.2009, 0.1239, 0.0965],\n",
       "           [0.1931, 0.1184, 0.0909],\n",
       "           ...,\n",
       "           [0.7838, 0.6348, 0.5524],\n",
       "           [0.7941, 0.6450, 0.5627],\n",
       "           [0.8007, 0.6517, 0.5693]],\n",
       " \n",
       "          [[0.2141, 0.1356, 0.1052],\n",
       "           [0.2116, 0.1324, 0.1026],\n",
       "           [0.2078, 0.1275, 0.0985],\n",
       "           ...,\n",
       "           [0.7911, 0.6465, 0.5627],\n",
       "           [0.7935, 0.6480, 0.5641],\n",
       "           [0.7950, 0.6489, 0.5651]],\n",
       " \n",
       "          [[0.2267, 0.1483, 0.1133],\n",
       "           [0.2283, 0.1456, 0.1121],\n",
       "           [0.2307, 0.1416, 0.1102],\n",
       "           ...,\n",
       "           [0.8025, 0.6646, 0.5785],\n",
       "           [0.7925, 0.6525, 0.5664],\n",
       "           [0.7861, 0.6447, 0.5585]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0257, 0.0220, 0.0141],\n",
       "           [0.0287, 0.0249, 0.0170],\n",
       "           [0.0333, 0.0293, 0.0215],\n",
       "           ...,\n",
       "           [0.4858, 0.3445, 0.2507],\n",
       "           [0.4782, 0.3372, 0.2434],\n",
       "           [0.4733, 0.3325, 0.2387]],\n",
       " \n",
       "          [[0.0236, 0.0221, 0.0143],\n",
       "           [0.0265, 0.0241, 0.0162],\n",
       "           [0.0310, 0.0271, 0.0193],\n",
       "           ...,\n",
       "           [0.4854, 0.3422, 0.2724],\n",
       "           [0.4717, 0.3333, 0.2513],\n",
       "           [0.4629, 0.3277, 0.2377]],\n",
       " \n",
       "          [[0.0222, 0.0222, 0.0144],\n",
       "           [0.0251, 0.0236, 0.0157],\n",
       "           [0.0295, 0.0257, 0.0179],\n",
       "           ...,\n",
       "           [0.4851, 0.3407, 0.2864],\n",
       "           [0.4675, 0.3309, 0.2564],\n",
       "           [0.4561, 0.3245, 0.2371]]],\n",
       " \n",
       " \n",
       "         [[[0.2059, 0.1275, 0.1000],\n",
       "           [0.2009, 0.1239, 0.0965],\n",
       "           [0.1931, 0.1184, 0.0909],\n",
       "           ...,\n",
       "           [0.7838, 0.6348, 0.5524],\n",
       "           [0.7941, 0.6450, 0.5627],\n",
       "           [0.8007, 0.6517, 0.5693]],\n",
       " \n",
       "          [[0.2141, 0.1356, 0.1052],\n",
       "           [0.2116, 0.1324, 0.1026],\n",
       "           [0.2078, 0.1275, 0.0985],\n",
       "           ...,\n",
       "           [0.7911, 0.6465, 0.5627],\n",
       "           [0.7935, 0.6480, 0.5641],\n",
       "           [0.7950, 0.6489, 0.5651]],\n",
       " \n",
       "          [[0.2267, 0.1483, 0.1133],\n",
       "           [0.2283, 0.1456, 0.1121],\n",
       "           [0.2307, 0.1416, 0.1102],\n",
       "           ...,\n",
       "           [0.8025, 0.6646, 0.5785],\n",
       "           [0.7925, 0.6525, 0.5664],\n",
       "           [0.7861, 0.6447, 0.5585]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0257, 0.0220, 0.0141],\n",
       "           [0.0287, 0.0249, 0.0170],\n",
       "           [0.0333, 0.0293, 0.0215],\n",
       "           ...,\n",
       "           [0.4858, 0.3445, 0.2507],\n",
       "           [0.4782, 0.3372, 0.2434],\n",
       "           [0.4733, 0.3325, 0.2387]],\n",
       " \n",
       "          [[0.0236, 0.0221, 0.0143],\n",
       "           [0.0265, 0.0241, 0.0162],\n",
       "           [0.0310, 0.0271, 0.0193],\n",
       "           ...,\n",
       "           [0.4854, 0.3422, 0.2724],\n",
       "           [0.4717, 0.3333, 0.2513],\n",
       "           [0.4629, 0.3277, 0.2377]],\n",
       " \n",
       "          [[0.0222, 0.0222, 0.0144],\n",
       "           [0.0251, 0.0236, 0.0157],\n",
       "           [0.0295, 0.0257, 0.0179],\n",
       "           ...,\n",
       "           [0.4851, 0.3407, 0.2864],\n",
       "           [0.4675, 0.3309, 0.2564],\n",
       "           [0.4561, 0.3245, 0.2371]]],\n",
       " \n",
       " \n",
       "         [[[0.2059, 0.1275, 0.1000],\n",
       "           [0.2009, 0.1239, 0.0965],\n",
       "           [0.1931, 0.1184, 0.0909],\n",
       "           ...,\n",
       "           [0.7838, 0.6348, 0.5524],\n",
       "           [0.7941, 0.6450, 0.5627],\n",
       "           [0.8007, 0.6517, 0.5693]],\n",
       " \n",
       "          [[0.2141, 0.1356, 0.1052],\n",
       "           [0.2116, 0.1324, 0.1026],\n",
       "           [0.2078, 0.1275, 0.0985],\n",
       "           ...,\n",
       "           [0.7911, 0.6465, 0.5627],\n",
       "           [0.7935, 0.6480, 0.5641],\n",
       "           [0.7950, 0.6489, 0.5651]],\n",
       " \n",
       "          [[0.2267, 0.1483, 0.1133],\n",
       "           [0.2283, 0.1456, 0.1121],\n",
       "           [0.2307, 0.1416, 0.1102],\n",
       "           ...,\n",
       "           [0.8025, 0.6646, 0.5785],\n",
       "           [0.7925, 0.6525, 0.5664],\n",
       "           [0.7861, 0.6447, 0.5585]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0257, 0.0220, 0.0141],\n",
       "           [0.0287, 0.0249, 0.0170],\n",
       "           [0.0333, 0.0293, 0.0215],\n",
       "           ...,\n",
       "           [0.4858, 0.3445, 0.2507],\n",
       "           [0.4782, 0.3372, 0.2434],\n",
       "           [0.4733, 0.3325, 0.2387]],\n",
       " \n",
       "          [[0.0236, 0.0221, 0.0143],\n",
       "           [0.0265, 0.0241, 0.0162],\n",
       "           [0.0310, 0.0271, 0.0193],\n",
       "           ...,\n",
       "           [0.4854, 0.3422, 0.2724],\n",
       "           [0.4717, 0.3333, 0.2513],\n",
       "           [0.4629, 0.3277, 0.2377]],\n",
       " \n",
       "          [[0.0222, 0.0222, 0.0144],\n",
       "           [0.0251, 0.0236, 0.0157],\n",
       "           [0.0295, 0.0257, 0.0179],\n",
       "           ...,\n",
       "           [0.4851, 0.3407, 0.2864],\n",
       "           [0.4675, 0.3309, 0.2564],\n",
       "           [0.4561, 0.3245, 0.2371]]]]),\n",
       " tensor([   79.,  2301., 44424.,  ...,     0.,     0.,     0.]),\n",
       " tensor([1., 1., 1.,  ..., 0., 0., 0.]),\n",
       " 64)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7.9000e+01, 2.3010e+03, 4.4424e+04, 2.5000e+01, 2.2000e+02, 3.1180e+03,\n",
       "        2.3503e+04, 1.1530e+03, 6.8000e+01, 3.6900e+02])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0][1][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import GPT2Tokenizer\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pregunta: Un paciente con derrame pleural está acompañado de una erupción sistémica, como se ve en la imagen (actualmente solo está disponible la imagen de la espalda). contexto:\"\"respuesta [\\'La psoriasis parece no tener relación con el derrame pleural.\\', \\'Psoriasis Típica\\', \\'Psoriasis\\', \\'Psoriasis Típica\\']<|endoftext|>!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(trainset[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_lens = []\n",
    "a_lens = []\n",
    "for i in range(len(test_dataset_es)):\n",
    "    question = test_dataset_es[i][2]\n",
    "    q_lens.append(len(tokenizer.encode(question)))\n",
    "# for answer in data_train['answers']:\n",
    "#     a_lens.append(len(tokenizer.encode(str(answer))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_track = 0\n",
    "for i in range(len(train_dataset_es)):\n",
    "    answer = train_dataset_es[i][3]\n",
    "    tokenized_answers = tokenizer.batch_encode_plus(answer)['input_ids']\n",
    "    curr_max = max([len(ans) for ans in tokenized_answers])\n",
    "    if curr_max > max_track:\n",
    "        max_track = curr_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_track"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "635"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.mean(q_lens)+2*np.std(q_lens)) # TRAIN: 388, max is 635\n",
    "np.max(q_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "343"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(np.mean(q_lens)+2*np.std(q_lens)) # TEST: 343"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
